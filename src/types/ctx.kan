import ":std/dbg";
import ":std/map";
import ":std/str";
import ":std/vec";

import ":ast/mod";
import ":ast/tyid";
import ":util" as _;
import ":source/span";
import ":memory/arena";

import ":error" as e;
import ":cli/report" as report;

import "util";
import "scope";

import "info" as _;
import "types" as _;
import "graph";

import "function";
import "template";
import "primitive";

type Pass enum {
    Functions, Templates
}

type ModuleContext struct {
    module: *mod.Module,
    // this holds the types of lvalues, for later lookup by name
    values: scope.ScopeStack,
    // this holds declared types, e.g. structs
    types: scope.ScopeStack,
    // this holds declared declarations, so signatures or templates
    decls: scope.ScopeStack,
    // this holds the imported modules with the alias as key
    imports: map.Map, // map.Map[str.View, *mod.Module]
    // the template pass will be repeated, until this is false for all modules.
    // This is needed, because templates can instantiate other templates with different type
    // parameters and there is no way to know the amount of templates we will get at the end
    // see: Compiler.infer_and_check_types() and InstanceSet.checked for more info
    // TODO: this is suboptimal, because templates will be checked twice
    had_unchecked_templates: bool
}

def (ctx: *ModuleContext) free() {
    ctx.values.free();
    ctx.types.free();
    ctx.decls.free();
    ctx.imports.free();
}

// the context used while type checking
type TyCtx struct {
    ty_arena: *arena.TypedArena,
    node_arena: *arena.TypedArena,
    temp_arena: arena.TypedArena,

    module_contexts: vec.Vec, // vec.Vec[ModuleContext]
    // since we create the vec with the correct capacity, it is safe to keep a pointer here
    current_module: *ModuleContext,

    call_graph: *graph.TypeGraph,

    current_pass: Pass,

    // the current functions signature or null, if in global scope
    current_signature: *Type,
    final_i32_ty: *Type,
    final_f32_ty: *Type
}

def create(
    ty_arena: *arena.TypedArena,
    node_arena: *arena.TypedArena,
    call_graph: *graph.TypeGraph,
    num_mods: usize
): TyCtx {
    dbg.assert(ty_arena.elem_size == sizeof Type, "invalid memory ty_arena");
    dbg.assert(node_arena.elem_size == sizeof TypeNode, "wrong type node arena size");

    let temp_arena = arena.typed(sizeof Type);

    return TyCtx {
        ty_arena: ty_arena,
        node_arena: node_arena,
        temp_arena: temp_arena,
        module_contexts: vec.with_cap(sizeof ModuleContext, num_mods),
        current_module: null,
        call_graph: call_graph,
        current_pass: Pass.Functions,
        current_signature: null,
        final_i32_ty: null,
        final_f32_ty: null
    };
}

def (ctx: *TyCtx) free() {
    for let i: usize = 0; i < ctx.module_contexts.len; i += 1 {
        (ctx.module_contexts.get_ptr(i) as *ModuleContext).free();
    }
    ctx.module_contexts.free();
    ctx.temp_arena.free();
}

def (ctx: *TyCtx) current_module_had_unchecked_templates(): bool {
    return ctx.current_module.had_unchecked_templates;
}

def (ctx: *TyCtx) set_current_module_had_unchecked_templates(value: bool) {
    ctx.current_module.had_unchecked_templates = value;
}

def (ctx: *TyCtx) set_module(module: *mod.Module) {
    // module already in map
    if module.index < ctx.module_contexts.len {
        ctx.current_module = ctx.module_contexts.get_ptr(module.index) as *ModuleContext;
        return;
    }

    dbg.assert(module.index == ctx.module_contexts.len, "modules are not iterated sequentially");

    let imports = map.with_cap(module.imports.len);
    for let i: usize = 0; i < module.imports.len; i += 1 {
        let imported = module.import_at(i);
        imports.insert(map.key(imported.alias.as_view()), imported.mod as *void);
    }

    let mod_ctx = ModuleContext {
        module: module,
        values: scope.scope_stack(),
        types: scope.scope_stack(),
        decls: scope.scope_stack(),
        imports: imports,
        had_unchecked_templates: true
    };
    ctx.module_contexts.push(&mod_ctx as *void);
    ctx.current_module = ctx.module_contexts.get_ptr(module.index) as *ModuleContext;
}

def (ctx: *TyCtx) open_scope() {
    ctx.current_module.values.open();
    ctx.current_module.types.open();
    ctx.current_module.decls.open();
}

def (ctx: *TyCtx) close_scope() {
    ctx.current_module.values.close();
    ctx.current_module.types.close();
    ctx.current_module.decls.close();
}

def (ctx: *TyCtx) alloc_final_ty(): *Type {
    return ctx.ty_arena.alloc() as *Type;
}

def (ctx: *TyCtx) alloc_ty(): *Type {
    return ctx.temp_arena.alloc() as *Type;
}

def (ctx: *TyCtx) alloc_node(): *TypeNode {
    return ctx.node_arena.alloc() as *TypeNode;
}

// a type variable to any
def (ctx: *TyCtx) any_var(): *Type {
    let anyTy = ctx.alloc_ty();
    anyTy.kind = TypeKind.Any;

    let var = ctx.alloc_ty();
    var.kind = TypeKind.Variable;
    var.data.inner = anyTy;
    return var;
}

// a type variable to anyInt
def (ctx: *TyCtx) any_var_int(): *Type {
    let anyIntTy = ctx.alloc_ty();
    anyIntTy.kind = TypeKind.AnyInt;

    let var = ctx.alloc_ty();
    var.kind = TypeKind.Variable;
    var.data.inner = anyIntTy;
    return var;
}

def (ctx: *TyCtx) any_var_float(): *Type {
    let anyFloatTy = ctx.alloc_ty();
    anyFloatTy.kind = TypeKind.AnyFloat;

    let var = ctx.alloc_ty();
    var.kind = TypeKind.Variable;
    var.data.inner = anyFloatTy;
    return var;
}

def (ctx: *TyCtx) error_type(): *Type {
    let error = ctx.alloc_ty();
    error.kind = TypeKind.Error;
    return error;
}

def (ctx: *TyCtx) get_current_signature(): *function.Signature {
    if ctx.current_signature == null {
        return null;
    }
    return &ctx.current_signature.data.signature;
}

def lookup_in(name: str.View, stack: *scope.ScopeStack): *Type {
    let item: scope.BoundItem = undefined;
    if stack.lookup(name, &item).is_error() {
        return null;
    }

    return item.ty;
}

def (ctx: *TyCtx) lookup_type(name: str.View): *Type {
    return lookup_in(name, &ctx.current_module.types);
}

def (ctx: *TyCtx) lookup_value(name: str.View): *Type {
    return lookup_in(name, &ctx.current_module.values);
}

def (ctx: *TyCtx) lookup_decl(name: str.View): *Type {
    return lookup_in(name, &ctx.current_module.decls);
}

def (ctx: *TyCtx) lookup_module(name: str.View): *mod.Module {
    return ctx.current_module.imports.get(map.key(name)) as *mod.Module;
}

def (ctx: *TyCtx) lookup_tyid(ty: *tyid.Type): *Type {
    if ty.kind == tyid.TypeKind.Ptr {
        let inner = ctx.lookup_tyid(ty.inner());
        if inner == null {
            return null;
        }
        return ctx.alloc_ty().init_ptr(inner);
    }

    if ty.kind == tyid.TypeKind.Slice {
        let inner = ctx.lookup_tyid(ty.inner());
        if inner == null {
            return null;
        }
        return ctx.alloc_ty().init_slice(inner);
    }

    let p = &ty.data.path;
    dbg.assert(p.segments.len == 1, "TODO(#26): handle arbitrary tyid segments");

    return ctx.lookup_type(p.segment_at(0).as_view());
}

def bind_in(name: str.View, ty: *Type, vis: Visibility, stack: *scope.ScopeStack, declared_at: *span.Span) {
    let item = scope.BoundItem {
        ty: ty,
        vis: vis,
        declared_at: declared_at
    };
    stack.bind(name, item);
}

def (ctx: *TyCtx) bind_decl_public(name: str.View, ty: *Type, declared_at: *span.Span) {
    dbg.assert(
        ty.kind == TypeKind.Signature || ty.kind == TypeKind.Template,
        "expected signature or template"
    );
    bind_in(name, ty, Visibility.Public, &ctx.current_module.decls, declared_at);
}

def (ctx: *TyCtx) bind_value_public(name: str.View, ty: *Type, declared_at: *span.Span) {
    bind_in(name, ty, Visibility.Public, &ctx.current_module.values, declared_at);
}

def (ctx: *TyCtx) bind_type_public(name: str.View, ty: *Type, declared_at: *span.Span) {
    bind_in(name, ty, Visibility.Public, &ctx.current_module.types, declared_at);
}

def (ctx: *TyCtx) call_graph_node(signature: *Type): *graph.Node {
    return ctx.call_graph.add_node(signature);
}

def (ctx: *TyCtx) register_call(caller_function: *Type, callee_function: *Type) {
    dbg.assert(caller_function.kind == TypeKind.Signature, "invalid typekind for call");
    if callee_function.kind != TypeKind.Signature {
        // this will be the case if we call function pointers
        // in that case, we cannot actually put the call into the graph, since the function which
        // will actually be called might not be known at compile time
        return;
    }

    let caller_sig = &caller_function.data.signature;
    let callee_sig = &callee_function.data.signature;

    if callee_sig.call_graph_node == null {
        callee_sig.call_graph_node = ctx.call_graph_node(callee_function);
    }
    if caller_sig.call_graph_node == null {
        caller_sig.call_graph_node = ctx.call_graph_node(caller_function);
    }

    let caller = caller_sig.call_graph_node;
    let callee = callee_sig.call_graph_node;

    ctx.call_graph.add_edge(graph.EdgeKind.Hard, caller, callee);
}

def (ctx: *TyCtx) unify(a: *Type, previous: *Type): *Type {
    if a == previous {
        return a;
    }

    let left = a.checked_var_innermost();
    let right = previous.checked_var_innermost();

    if left == right {
        return a;
    }

    if ctx.is_concrete_version_of(a, previous) {
        dbg.assert(previous.is_variable(), "previous is not a variable");
        // point the innermost variable to a instead
        *previous.var_innermost() = a;
        return a;
    }

    if ctx.is_less_concrete_version_of(a, previous) {
        dbg.assert(a.is_variable(), "expression type is not a variable");
        *a.var_innermost() = previous;
        return previous;
    }

    // both pointer || both slice
    if left.kind == right.kind && left.is_const_size_indirect_type() {
        let inner = ctx.unify(left.data.ptr_or_slice_to, right.data.ptr_or_slice_to);
        if inner == null {
            return null;
        }

        left.data.ptr_or_slice_to = inner;
        return a;
    }

    if left.equals(right) {
        if a.is_variable() {
            *a.var_innermost() = previous;
            return previous;
        } else if previous.is_variable() {
            *previous.var_innermost() = a;
            return a;
        } else {
            a.kind = TypeKind.Variable;
            a.data.inner = previous;
        }

        return a;
    }

    return null;
}

// checks if other is a less concrete version of t
def (ctx: *TyCtx) is_concrete_version_of(t: *Type, other: *Type): bool {
    while t.is_variable() {
        t = t.data.inner;
    }
    while other.is_variable() {
        other = other.data.inner;
    }

    return other.kind == TypeKind.Any
        || t.kind == TypeKind.Int && other.kind == TypeKind.AnyInt
        || t.kind == TypeKind.Float && other.kind == TypeKind.AnyFloat;
}

// checks if t is a less concrete version of other
def (ctx: *TyCtx) is_less_concrete_version_of(t: *Type, other: *Type): bool {
    while t.is_variable() {
        t = t.data.inner;
    }
    while other.is_variable() {
        other = other.data.inner;
    }

    return t.kind == TypeKind.Any
        || t.kind == TypeKind.AnyInt && other.kind == TypeKind.Int
        || t.kind == TypeKind.AnyFloat && other.kind == TypeKind.Float;
}

// this will get the actual function type for a callable type or null, if the types was not callable
// in the case of a template, it will initialize all generic parameters using the allocator
def (ctx: *TyCtx) get_function(t: *Type): *Type {
    if t.kind == TypeKind.Variable {
        return ctx.get_function(t.data.inner);
    }

    if t.kind == TypeKind.Function {
        return t;
    }

    if t.kind == TypeKind.Signature {
        return t.data.signature.func;
    }

    if t.kind == TypeKind.Template {
        let f = ctx.get_function(t.data.template.inner);
        if f == null {
            return null;
        }

        let map = ctx.monomorph_map(&t.data.template);
        defer map.free();

        let monomorphed = ctx.alloc_ty().init_func(t.data.template.instances);
        monomorphed.data.function = f.data.function;
        monomorphed.data.function.params_head = null;
        let monomorphed_f = &monomorphed.data.function;

        let current_read = f.data.function.params_head;
        let current_write = &monomorphed_f.params_head;

        while current_read != null {
            let monomorphed_param = ctx.replace_param_type(&map, current_read.value);

            let name = current_read.name.data.ident;
            let new_node = ctx.alloc_node().init_ident(name, monomorphed_param);
            *current_write = new_node;

            current_write = &(*current_write).next;
            current_read = current_read.next;
        }

        monomorphed_f.ret = ctx.replace_param_type(&map, monomorphed_f.ret);
        return monomorphed;
    }

    return null;
}

def (ctx: *TyCtx) replace_param_type(monomorph_map: *map.Map, param: *Type): *Type {
    if param.kind == TypeKind.TemplateParam {
        let key = key_from_ident(param.data.template_param.name);
        let monomorphed = monomorph_map.get(key) as *Type;
        dbg.assert(monomorphed != null, "monomorphed is null");
        return monomorphed;
    }

    if param.kind == TypeKind.Ptr {
        let inner = ctx.replace_param_type(monomorph_map, param.data.ptr_or_slice_to);
        return ctx.alloc_ty().init_ptr(inner);
    }

    if param.kind == TypeKind.Slice {
        let inner = ctx.replace_param_type(monomorph_map, param.data.ptr_or_slice_to);
        return ctx.alloc_ty().init_slice(inner);
    }


    return param;
}

def (ctx: *TyCtx) monomorph_map(t: *template.Template): map.Map {
    let map = map.with_cap(t.num_params);
    let current = t.generics_head;
    while current != null {
        let param = current.value;
        let monomorphed = ctx.any_var();

        let key = key_from_ident(param.data.template_param.name);
        map.insert(key, monomorphed as *void);

        current = current.next;
    }
    return map;
}

let _final_i32_ty: *Type = null;
let _final_f32_ty: *Type = null;

def (ctx: *TyCtx) init_builtin_types() {
    let void_ty = ctx.alloc_ty().init_void();
    ctx.bind_type_public(str.view_from("void"), void_ty, null);

    let char_ty = ctx.alloc_ty().init_int(primitive.Signedness.Signed, size_bytes(1));
    ctx.bind_type_public(str.view_from("i8"), char_ty, null);

    let i16_ty = ctx.alloc_ty().init_int(primitive.Signedness.Signed, size_bytes(2));
    ctx.bind_type_public(str.view_from("i16"), i16_ty, null);

    let i32_ty = ctx.alloc_ty().init_int(primitive.Signedness.Signed, size_bytes(4));
    ctx.bind_type_public(str.view_from("i32"), i32_ty, null);

    let i64_ty = ctx.alloc_ty().init_int(primitive.Signedness.Signed, size_bytes(8));
    ctx.bind_type_public(str.view_from("i64"), i64_ty, null);

    let isize_ty = ctx.alloc_ty().init_int(primitive.Signedness.Signed, pointer_size_platform());
    ctx.bind_type_public(str.view_from("isize"), isize_ty, null);

    let u8_ty = ctx.alloc_ty().init_int(primitive.Signedness.Unsigned, size_bytes(1));
    ctx.bind_type_public(str.view_from("u8"), u8_ty, null);

    let u16_ty = ctx.alloc_ty().init_int(primitive.Signedness.Unsigned, size_bytes(2));
    ctx.bind_type_public(str.view_from("u16"), u16_ty, null);

    let u32_ty = ctx.alloc_ty().init_int(primitive.Signedness.Unsigned, size_bytes(4));
    ctx.bind_type_public(str.view_from("u32"), u32_ty, null);

    let u64_ty = ctx.alloc_ty().init_int(primitive.Signedness.Unsigned, size_bytes(8));
    ctx.bind_type_public(str.view_from("u64"), u64_ty, null);

    let usize_ty = ctx.alloc_ty().init_int(primitive.Signedness.Unsigned, pointer_size_platform());
    ctx.bind_type_public(str.view_from("usize"), usize_ty, null);

    let f32_ty = ctx.alloc_ty().init_float(size_bytes(4));
    ctx.bind_type_public(str.view_from("f32"), f32_ty, null);

    let f64_ty = ctx.alloc_ty().init_float(size_bytes(8));
    ctx.bind_type_public(str.view_from("f64"), f64_ty, null);

    let bool_ty = ctx.alloc_ty().init_bool();
    ctx.bind_type_public(str.view_from("bool"), bool_ty, null);

    let string_ty = ctx.alloc_ty().init_slice(char_ty);
    ctx.bind_type_public(str.view_from("string"), string_ty, null);

    if _final_f32_ty != null {
        return;
    }

    // i32 and f32 are special, since they could be used before being moved in the finalize stage
    // also they are referenced directly inside TyCtx
    _final_i32_ty = ctx.alloc_final_ty();
    *_final_i32_ty = *i32_ty;
    ctx.final_i32_ty = _final_i32_ty;

    _final_f32_ty = ctx.alloc_final_ty();
    *_final_f32_ty = *f32_ty;
    ctx.final_f32_ty = _final_f32_ty;
}

