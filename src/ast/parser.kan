import "../std/dbg";
import "../std/str";
import "../std/vec";

import "../cli/report" as _report; // rename this, so I don't use it instead of Parser.report()
import "../error" as e;
import "../memory/arena";
import "../util" as _;

import "../source/span";
import "../source/ident";

import "tyid";
import "item";
import "stmt" as _;
import "expr" as _;
import "signature" as sig;

import "lexer" as l;
import "token" as tok;

type Parser struct {
    had_error: bool,
    panic_mode: bool,
    lexer: l.Lexer,
    ast_arena: *arena.TypedArena,
    ty_arena: *arena.TypedArena,
    expr_arena: *arena.TypedArena
}

def create(
    lexer: l.Lexer,
    ast_arena: *arena.TypedArena,
    ty_arena: *arena.TypedArena,
    expr_arena: *arena.TypedArena
): Parser {
    dbg.assert(ast_arena.elem_size == sizeof item.Item, "wrong ast arena size");
    dbg.assert(expr_arena.elem_size == sizeof Expr, "wrong expr arena size");
    dbg.assert(ty_arena.elem_size == sizeof tyid.Type, "wrong ty arena size");

    return Parser {
        had_error: false,
        panic_mode: false,
        lexer: lexer,
        ast_arena: ast_arena,
        ty_arena: ty_arena,
        expr_arena: expr_arena
    };
}

def (p: *Parser) alloc_item(): *item.Item {
    return p.ast_arena.alloc() as *item.Item;
}

def (p: *Parser) alloc_tyid(): *tyid.Type {
    return p.ty_arena.alloc() as *tyid.Type;
}

def (p: *Parser) alloc_expr(): *Expr {
    return p.expr_arena.alloc() as *Expr;
}

def (p: *Parser) peek(): tok.Token {
    return p.lexer.peek();
}

def (p: *Parser) advance(): tok.Token {
    let current = p.lexer.next_token();

    while current.ty.is_err() {
        let lexeme = current.lexeme();
        let error = e.string_single(e.ErrorKind.UnknownToken, current.span, lexeme);
        p.report(&error);

        current = p.lexer.next_token();
    }

    return current;
}

def (p: *Parser) check(ty: tok.TokenType): bool {
    return p.peek().ty == ty;
}

def (p: *Parser) is_at_end(): bool {
    return p.check(tok.TokenType.EOF);
}

// consumes a token of the specified type, or does nothing
// returns true, if a token was consumed
def (p: *Parser) consume_optional(ty: tok.TokenType): bool {
    if p.check(ty) {
        p.advance();
        return true;
    }
    return false;
}

// this will first check, if the next token the lexer would produce, will be of the expected
// type, if it is, it will set out to the consumed token and return Result.OK
// if the token type differs, it will report a parse error and return Result.Error.
// In the latter case, the value of out is undefined
// Any error tokens will be skipped and reported. If the expected token follows after some
// amount of error tokens, this will succeed, but report the first error that was encountered during
// skipping.
def (p: *Parser) consume_tok(expected: tok.TokenType, out: *tok.Token): Result {
    if p.check(expected) {
        *out = p.advance();
        return Result.OK;
    }

    // skip all error tokens so that we don't report 2 errors for a single wrong token
    // (UnknownToken + ExpectedButGot)
    if p.peek().ty.is_err() {
        let next_after_errors = p.advance();
        if next_after_errors.ty == expected {
            *out = next_after_errors;
            return Result.OK;
        }
    }

    // if we get here, report the consume error (ExpectedButGot)
    p.report_expected_but_got(expected.as_view());
    return Result.Error;
}

// same as consume_tok, but always discards the consumed token
def (p: *Parser) consume(expected: tok.TokenType): Result {
    let out: tok.Token = undefined;
    return p.consume_tok(expected, &out);
}

def (p: *Parser) consume_ident(out: *ident.Ident): Result {
    let name_token: tok.Token = undefined;
    if p.consume_tok(tok.TokenType.Ident, &name_token).is_error() {
        return Result.Error;
    }

    *out = ident.from_span(name_token.span);
    return Result.OK;
}

// consume a type identifier into the previously allocated memory
// the caller has to ensure, that tyid.Type.free is called in the case of an error.
// However, this should be handled by the arena
def (p: *Parser) consume_tyid(memory: *tyid.Type): Result {
    // if the type starts with '*', it's a pointer. The inner type will be parsed recursively
    if p.consume_optional(tok.TokenType.Star) {
        let inner = p.alloc_tyid();
        tyid.init_pointer(memory, inner);
        return p.consume_tyid(inner);
    }

    tyid.init_path(memory);
    let path = &memory.data.path;

    // a segment is just an identifier
    // a Path can consist of an arbitrary amount of Segments, which are connected by dots
    // e.g. tyid.Type.free has 3 segments
    let segment: ident.Ident = undefined;
    if p.consume_ident(&segment).is_error() {
        return Result.Error;
    }
    path.push_segment(segment);

    while p.check(tok.TokenType.Dot) {
        p.advance();
        if p.consume_ident(&segment).is_error() {
            return Result.Error;
        }
        path.push_segment(segment);
    }

    return Result.OK;
}

def (p: *Parser) report_expected_but_got(expected: str.View) {
    let actual = p.peek().ty.as_view();
    let error = e.string_tuple(e.ErrorKind.ExpectedButGot, p.peek().span, expected, actual);
    p.report(&error);
}

// report an error. If the parser is currently in panic mode, the error will be silently
// discarded
def (p: *Parser) report(error: *e.Error) {
    if p.panic_mode {
        return;
    }

    p.panic_mode = p.had_error = true;
    _report.print_error(error);
}

// try to synchronize the compiler. This will skip tokens until we are at the beginning of a new
// stmt or EOF
def (p: *Parser) sync() {
    p.panic_mode = false;

    let previous = p.advance();
    while !p.check(tok.TokenType.EOF) {
        if previous.ty == tok.TokenType.Semi {
            return;
        }

        let current = p.peek();
        if current.ty == tok.TokenType.Import {
            return;
        }

        previous = p.advance();
    }
}

// Basically a Result type for import parsing, since ImportDeclarations aren't Items, we cannot
// put them inside the item arena. So we just store them in a separate Vec by value
type ParsedImport struct {
    // since we return the parsed import by value, we have to somehow mark the last import
    is_present: bool,
    // we want to report every error, so we have to treat a missing import different than an
    // erroneous one
    was_error: bool,
    import_decl: item.ImportDeclaration
}

def empty_import(): ParsedImport {
    return ParsedImport { is_present: false, was_error: false, import_decl: undefined };
}

def error_import(): ParsedImport {
    return ParsedImport { is_present: false, was_error: true, import_decl: undefined };
}

// since all imports have to be declared at the top of the file, they can be parsed separate
// from all the other items. This is important for dependency resolution between files, to avoid
// parsing files, that aren't even included (e.g. the stdlib)
def (p: *Parser) parse_next_import(): ParsedImport {
    if !p.check(tok.TokenType.Import) {
        return empty_import();
    }

    // consume 'import'
    p.advance();

    let import_path: tok.Token = undefined;
    if p.consume_tok(tok.TokenType.String, &import_path).is_error() {
        p.sync();
        return error_import();
    }

    if p.consume(tok.TokenType.Semi).is_error() {
        p.sync();
        return error_import();
    }

    let decl = item.ImportDeclaration {
        path: ident.from_span(import_path.span),
        alias: ident.empty()
    };

    return ParsedImport { is_present: true, was_error: false, import_decl: decl };
}

def (p: *Parser) parse_item(): *item.Item {
    // in this model, the caller (this function) allocates the memory neccessary to store an item
    let item: *item.Item = null;

    if p.check(tok.TokenType.Def) && p.parse_func_def(item = p.alloc_item()).is_ok() {
        return item;
    }

    p.report_expected_but_got(str.view_from("def"));
    if p.panic_mode {
        p.sync();
    }

    return null;
}

def (p: *Parser) parse_stmt(memory: *Stmt): Result {
    memory.init_expr();
    if p.parse_expr(&memory.data.expr).is_error() {
        return Result.Error;
    }

    if p.consume(tok.TokenType.Semi).is_error() {
        return Result.Error;
    }

    return Result.OK;
}

// parse a single functino definition and store it in 'memory'
def (p: *Parser) parse_func_def(memory: *item.Item): Result {
    memory.init_func_def();

    let def_token: tok.Token = undefined;
    if p.consume_tok(tok.TokenType.Def, &def_token).is_error() {
        return Result.Error;
    }

    let name: ident.Ident = undefined;
    if p.consume_ident(&name).is_error() {
        return Result.Error;
    }
    memory.name = name;

    let params = &memory.data.func_def.sig.params;
    let end_span = span.empty();
    p.parse_param_list(params, &end_span);

    if p.consume_optional(tok.TokenType.Colon) {
        let ty = p.alloc_tyid();
        if p.consume_tyid(ty).is_error() {
            return Result.Error;
        }
    }

    let block = &memory.data.func_def.block;
    if p.parse_block(block).is_error() {
        return Result.Error;
    }

    return Result.OK;
}

// parses the parameter list for a function declaration
// the parsed parameters are pushed into the 'params' vec and the span of the closing ')' is
// returned via the rparen_span parameter
// it does allow for a comma after the last parameter, but not in front of the first
// see grammar.ebnf -> ParameterList for more information
def (p: *Parser) parse_param_list(params: *vec.Vec, rparen_span: *span.Span): Result {
    if p.consume(tok.TokenType.LParen).is_error() {
        return Result.Error;
    }

    let first = true;

    // since we allow for trailing ',', we have to check for the closing ')'
    while !p.check(tok.TokenType.RParen) {
        // there should be no comma infront of the first parameter, so we can just skip this
        if !first {
            // every other parameter should be preceeded by a ','
            if p.consume(tok.TokenType.Comma).is_error() {
                return Result.Error;
            }

            // this allows for a trailing comma after the last parameter
            if p.check(tok.TokenType.RParen) {
                break;
            }
        }
        first = false;

        // a parameter has the form 'name: ty'
        let name: ident.Ident = undefined;
        if p.consume_ident(&name).is_error() {
            return Result.Error;
        }

        if p.consume(tok.TokenType.Colon).is_error() {
            return Result.Error;
        }

        let ty = p.alloc_tyid();
        if p.consume_tyid(ty).is_error() {
            return Result.Error;
        }

        let param = sig.param(name, ty);
        params.push(&param as *void);
    }

    let closing_rparen: tok.Token = undefined;
    if p.consume_tok(tok.TokenType.RParen, &closing_rparen).is_error() {
        return Result.Error;
    }

    *rparen_span = closing_rparen.span;
    return Result.OK;
}

def (p: *Parser) parse_block(block: *Block): Result {
    if p.consume(tok.TokenType.LBrace).is_error() {
        return Result.Error;
    }

    while !(p.is_at_end() || p.check(tok.TokenType.RBrace)) {
        // we reserve memory inside the block and the parse directly into it
        let stmt = block.reserve();
        if p.parse_stmt(stmt).is_error() {
            return Result.Error;
        }
        // mark the reserved memory inside the block as initialized
        block.push_reserved();
    }

    if p.consume(tok.TokenType.RBrace).is_error() {
        return Result.Error;
    }

    return Result.OK;
}

def (p: *Parser) parse_expr(memory: *Expr): Result {
    return p.parse_precedence(memory, tok.Precedence.Assign);
}

// parse an expression with a certain start precedence (current). This will consume tokens
// until a token with a lower precedence than 'current' is found
// the resulting expression is stored in 'memory'
def (p: *Parser) parse_precedence(memory: *Expr, current: tok.Precedence): Result {
    if p.parse_prefix(memory).is_error() {
        return Result.Error;
    }

    while p.next_higher_precedence(current) {
        // copy the old prefix expression data...
        let prefix = p.alloc_expr();
        *prefix = *memory;
        // ... since we overwrite it here
        if p.parse_infix(memory, prefix).is_error() {
            return Result.Error;
        }
    }

    return Result.OK;
}

def (p: *Parser) next_higher_precedence(current: tok.Precedence): bool {
    return p.peek().ty.precedence() > current;
}

// parse a prefix expression. e.g. a literal or a unary expression
// the parsed expression will be initialized into 'memory'
def (p: *Parser) parse_prefix(memory: *Expr): Result {
    let token = p.advance();

    if token.ty == tok.TokenType.Int {
        memory.init_int(token);
        return Result.OK;
    }

    return Result.Error;
}

// parse an infix expression. e.g. a binary expression
// the parsed expression will be initialized into 'memory'
def (p: *Parser) parse_infix(memory: *Expr, left: *Expr): Result {
    let token = p.advance();

    if token.ty == tok.TokenType.Plus {
        let right = p.alloc_expr();
        let precedence = token.ty.precedence().next_higher();
        if p.parse_precedence(right, precedence).is_error() {
            return Result.Error;
        }

        memory.init_binary(BinaryKind.Add, left, right);
        return Result.OK;
    }

    return Result.Error;
}
