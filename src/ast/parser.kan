import ":std/dbg";
import ":std/str";
import ":std/vec";

import ":cli/report" as _report; // rename this, so I don't use it instead of Parser.report()
import ":error" as e;
import ":memory/arena";
import ":util" as _;

import ":source/span";
import ":source/ident";

import "ast";
import "tyid";
import "item";
import "stmt" as _;
import "expr" as _;
import "generics" as g;
import "signature" as sig;

import "lexer" as l;
import "token" as tok;

type Parser struct {
    panic_mode: bool,
    error_count: usize,
    lexer: l.Lexer,
    arenas: *ast.Arenas
}

def create(lexer: l.Lexer, arenas: *ast.Arenas): Parser {
    return Parser {
        panic_mode: false,
        error_count: 0,
        lexer: lexer,
        arenas: arenas
    };
}

def (p: *Parser) alloc_item(): *item.Item {
    return p.arenas.item.alloc() as *item.Item;
}

def (p: *Parser) alloc_tyid(): *tyid.Type {
    return p.arenas.tyid.alloc() as *tyid.Type;
}

def (p: *Parser) alloc_stmt(): *Stmt {
    return p.arenas.stmt.alloc() as *Stmt;
}

def (p: *Parser) alloc_expr(): *Expr {
    return p.arenas.expr.alloc() as *Expr;
}

def (p: *Parser) alloc_expr_node(): *ExprNode {
    return p.arenas.node.alloc() as *ExprNode;
}

def (p: *Parser) peek(): tok.Token {
    return p.lexer.peek();
}

def (p: *Parser) advance(): tok.Token {
    let current = p.lexer.next_token();

    while current.ty.is_err() {
        let error = e.simple_error(e.ErrorKind.CouldNotScanToken, current.span);
        let note = e.simple_note(current.ty.as_view());
        error.add_note(&note);
        p.report(&error);

        current = p.lexer.next_token();
    }

    return current;
}

def (p: *Parser) check(ty: tok.TokenType): bool {
    return p.peek().ty == ty;
}

def (p: *Parser) is_at_end(): bool {
    return p.check(tok.TokenType.EOF);
}

// consumes a token of the specified type, or does nothing
// returns true, if a token was consumed
def (p: *Parser) consume_optional(ty: tok.TokenType): bool {
    if p.check(ty) {
        p.advance();
        return true;
    }
    return false;
}

// see consume_optional and consume_tok
def (p: *Parser) consume_optional_tok(ty: tok.TokenType, out: *tok.Token): bool {
    if p.check(ty) {
        *out = p.advance();
        return true;
    }
    return false;
}

// this will first check, if the next token the lexer would produce, will be of the expected
// type, if it is, it will set out to the consumed token and return Result.OK
// if the token type differs, it will report a parse error and return Result.Error.
// In the latter case, the value of out is undefined
// Any error tokens will be skipped and reported. If the expected token follows after some
// amount of error tokens, this will succeed, but report the first error that was encountered during
// skipping.
def (p: *Parser) consume_tok(expected: tok.TokenType, out: *tok.Token): Result {
    if p.check(expected) {
        *out = p.advance();
        return Result.OK;
    }

    // skip all error tokens so that we don't report 2 errors for a single wrong token
    // (UnknownToken + ExpectedButGot)
    if p.peek().ty.is_err() {
        let next_after_errors = p.advance();
        if next_after_errors.ty == expected {
            *out = next_after_errors;
            return Result.OK;
        }
    }

    // if we get here, report the consume error (ExpectedButGot)
    p.report_expected_but_got(expected.as_view());
    return Result.Error;
}

// same as consume_tok, but always discards the consumed token
def (p: *Parser) consume(expected: tok.TokenType): Result {
    let out: tok.Token = undefined;
    return p.consume_tok(expected, &out);
}

def (p: *Parser) consume_ident(out: *ident.Ident): Result {
    let name_token: tok.Token = undefined;
    if p.consume_tok(tok.TokenType.Ident, &name_token).is_error() {
        return Result.Error;
    }

    *out = ident.from_span(name_token.span);
    return Result.OK;
}

// consume a type identifier into the previously allocated memory
// the caller has to ensure, that tyid.Type.free is called in the case of an error.
// However, this should be handled by the arena
def (p: *Parser) consume_tyid(memory: *tyid.Type): Result {
    // if the type starts with '*', it's a pointer. The inner type will be parsed recursively
    let star: tok.Token = undefined;
    if p.consume_optional_tok(tok.TokenType.Star, &star) {
        let inner = p.alloc_tyid();
        tyid.init_pointer(memory, inner);
        if p.consume_tyid(inner).is_error() {
            return Result.Error;
        }

        memory.span = star.span.merge(inner.span);
        return Result.OK;
    }

    // if the type starts with '[]', it's a slice. The inner type will be parsed recursively
    let left_bracket: tok.Token = undefined;
    if p.consume_optional_tok(tok.TokenType.LBracket, &left_bracket) {
        p.consume(tok.TokenType.RBracket);
        let inner = p.alloc_tyid();
        tyid.init_slice(memory, inner);
        if p.consume_tyid(inner).is_error() {
            return Result.Error;
        }

        memory.span = left_bracket.span.merge(inner.span);
        return Result.OK;
    }

    tyid.init_path(memory);
    let path = &memory.data.path;

    // a segment is just an identifier
    // a Path can consist of an arbitrary amount of Segments, which are connected by dots
    // e.g. tyid.Type.free has 3 segments
    let segment: ident.Ident = undefined;
    if p.consume_ident(&segment).is_error() {
        return Result.Error;
    }

    memory.span = segment.span;
    path.push_segment(segment);

    while p.check(tok.TokenType.Dot) {
        p.advance();
        if p.consume_ident(&segment).is_error() {
            return Result.Error;
        }
        memory.span = memory.span.merge(segment.span);
        path.push_segment(segment);
    }

    return Result.OK;
}

def (p: *Parser) report_expected_but_got(expected: str.View) {
    let actual = p.peek().ty.as_view();
    let error = e.string_tuple(e.ErrorKind.ExpectedButGot, p.peek().span, expected, actual);
    p.report(&error);
}

def (p: *Parser) report_simple(kind: e.ErrorKind, span: span.Span) {
    let error = e.simple_error(kind, span);
    p.report(&error);
}

// report an error. If the parser is currently in panic mode, the error will be silently
// discarded
def (p: *Parser) report(error: *e.Error) {
    if p.panic_mode {
        return;
    }

    p.panic_mode = true;
    p.error_count += 1;
    _report.print_error(error);
}

// try to synchronize the compiler. This will skip tokens until we are at the beginning of a new
// stmt or EOF
// it will return the span of the last consume token
def (p: *Parser) sync(): span.Span {
    p.panic_mode = false;

    let previous = p.advance();
    while !p.check(tok.TokenType.EOF) {
        if previous.ty == tok.TokenType.Semi {
            return previous.span;
        }

        let current = p.peek();
        // a synchronization point has been reached
        // this is either a new statement or a new item
        let is_at_new_beginning = current.ty == tok.TokenType.Import
             || current.ty == tok.TokenType.Def
             || current.ty == tok.TokenType.Return
             || current.ty == tok.TokenType.If
             || current.ty == tok.TokenType.Let;

        if is_at_new_beginning {
            return previous.span;
        }

        previous = p.advance();
    }

    return previous.span;
}

// Basically a Result type for import parsing, since ImportDeclarations aren't Items, we cannot
// put them inside the item arena. So we just store them in a separate Vec by value
type ParsedImport struct {
    // since we return the parsed import by value, we have to somehow mark the last import
    is_present: bool,
    // we want to report every error, so we have to treat a missing import different than an
    // erroneous one
    was_error: bool,
    import_decl: item.ImportDeclaration
}

def empty_import(): ParsedImport {
    return ParsedImport { is_present: false, was_error: false, import_decl: undefined };
}

def error_import(): ParsedImport {
    return ParsedImport { is_present: false, was_error: true, import_decl: undefined };
}

// since all imports have to be declared at the top of the file, they can be parsed separate
// from all the other items. This is important for dependency resolution between files, to avoid
// parsing files, that aren't even included (e.g. the stdlib)
def (p: *Parser) parse_next_import(): ParsedImport {
    if !p.check(tok.TokenType.Import) {
        return empty_import();
    }

    // consume 'import'
    p.advance();

    let import_path: tok.Token = undefined;
    if p.consume_tok(tok.TokenType.String, &import_path).is_error() {
        p.sync();
        return error_import();
    }

    if p.consume(tok.TokenType.Semi).is_error() {
        p.sync();
        return error_import();
    }

    let decl = item.ImportDeclaration {
        path: ident.from_span(import_path.span),
        alias: ident.empty()
    };

    return ParsedImport { is_present: true, was_error: false, import_decl: decl };
}

def (p: *Parser) parse_item(): *item.Item {
    // in this model, the caller (this function) allocates the memory neccessary to store an item
    let item: *item.Item = null;

    if p.check(tok.TokenType.Def) {
        if p.parse_func_def(item = p.alloc_item()).is_ok() {
            return item;
        }

        p.sync();
        return null;
    }

    p.report_expected_but_got(str.view_from("def"));
    p.sync();
    return null;
}

def (p: *Parser) statement(memory: *Stmt): Result {
    let error_count = p.error_count;
    let start = p.peek().span;

    if p.parse_stmt(memory).is_error() {
        let current = p.peek().span;
        if p.panic_mode {
            current = p.sync();
        }

        // an error occured, but we haven't reported anything yet, so we just use the generic
        // "failed to parse statement" error
        if p.error_count == error_count {
            p.report_simple(e.ErrorKind.CouldNotParseStmt, start.merge(current));
        }

        return Result.Error;
    }

    return Result.OK;
}

def (p: *Parser) parse_stmt(memory: *Stmt): Result {
    // CompoundStatements
    if p.check(tok.TokenType.LBrace) {
        memory.init_block();
        return p.parse_block(memory);
    } else if p.check(tok.TokenType.If) {
        memory.init_if();
        return p.parse_if(memory);
    }

    // all statements after this have to be followed by a semicolon (SimpleStatement)
    if p.check(tok.TokenType.Let) {
        memory.init_var_decl();
        if p.parse_let_binding(memory).is_error() {
            return Result.Error;
        }
    } else if p.check(tok.TokenType.Return){
        let ret_token: tok.Token = undefined;
        if p.consume_tok(tok.TokenType.Return, &ret_token).is_error() {
            return Result.Error;
        }

        memory.init_return();
        if !p.check(tok.TokenType.Semi) {
            memory.data.ret = p.alloc_expr();
            if p.expression(memory.data.ret, false).is_error() {
                return Result.Error;
            }
            memory.span = ret_token.span.merge(memory.data.ret.span);
        } else {
            memory.span = ret_token.span;
        }
    } else {
        memory.init_expr();
        if p.expression(&memory.data.expr, false).is_error() {
            return Result.Error;
        }
        // Parser.expression cannot initialize the stmt span, since it only gets the expr memory
        memory.span = memory.data.expr.span;
    }

    if p.consume(tok.TokenType.Semi).is_error() {
        return Result.Error;
    }

    return Result.OK;
}

// parse a single function definition and store it in 'memory'
def (p: *Parser) parse_func_def(memory: *item.Item): Result {
    let block = memory.data.func_def.block_stmt = p.alloc_stmt();
    memory.init_func_def();

    let def_token: tok.Token = undefined;
    if p.consume_tok(tok.TokenType.Def, &def_token).is_error() {
        return Result.Error;
    }
    memory.span = def_token.span;

    let signature = &memory.data.func_def.sig;

    // the generics (type parameters)
    let generics = &signature.generic_params;
    if p.parse_generics_list(generics).is_error() {
        return Result.Error;
    }

    let name: ident.Ident = undefined;
    if p.consume_ident(&name).is_error() {
        return Result.Error;
    }
    memory.name = name;

    // the parameters
    let params = &signature.params;
    let end_span = span.empty();
    if p.parse_param_list(params, &end_span).is_error() {
        return Result.Error;
    }
    memory.span.end = end_span.end;

    // the return type must be initialized even if there was no return type, since we might need
    // the span for error messages. In the case of a missing return type declaration, we just
    // use the closing ')' of the param list as the return type span
    let ret = sig.empty_return(end_span);

    // the optional return type
    if p.consume_optional(tok.TokenType.Colon) {
        let ty = p.alloc_tyid();
        if p.consume_tyid(ty).is_error() {
            return Result.Error;
        }
        // if we actually had a return type, we obviously use that instead of the 'ret' above
        ret = sig.return_from_tyid(ty);
    }
    memory.data.func_def.sig.ret = ret;

    if p.parse_block(block).is_error() {
        return Result.Error;
    }

    return Result.OK;
}

// parses the generic parameter list for a function declaration
// the parsed parameters are pushed into the 'params' vec
// it does allow for a comma after the last parameter, but not in front of the first
def (p: *Parser) parse_generics_list(params: *vec.Vec): Result {
    // generics are optional, so not having [ is legal
    if !p.consume_optional(tok.TokenType.LBracket) {
        return Result.OK;
    }

    let first = true;

    // since we allow for trailing ',', we have to check for the closing ']'
    while !p.check(tok.TokenType.RBracket) {
        // there should be no comma infront of the first parameter, so we can just skip this
        if !first {
            // every other parameter should be preceeded by a ','
            if p.consume(tok.TokenType.Comma).is_error() {
                return Result.Error;
            }

            // this allows for a trailing comma after the last parameter
            if p.check(tok.TokenType.RBracket) {
                break;
            }
        }
        first = false;

        // a parameter has the form 'name: ty'
        let name: ident.Ident = undefined;
        if p.consume_ident(&name).is_error() {
            return Result.Error;
        }

        let param = g.generic_param(name);
        params.push(&param as *void);
    }

    let closing_rbrace: tok.Token = undefined;
    if p.consume_tok(tok.TokenType.RBracket, &closing_rbrace).is_error() {
        return Result.Error;
    }

    if params.len == 0 {
        p.report_simple(e.ErrorKind.EmptyGenericsList, closing_rbrace.span);
        return Result.Error;
    }

    return Result.OK;
}

// parses the parameter list for a function declaration
// the parsed parameters are pushed into the 'params' vec and the span of the closing ')' is
// returned via the rparen_span parameter
// it does allow for a comma after the last parameter, but not in front of the first
// see grammar.ebnf -> ParameterList for more information
def (p: *Parser) parse_param_list(params: *vec.Vec, rparen_span: *span.Span): Result {
    if p.consume(tok.TokenType.LParen).is_error() {
        return Result.Error;
    }

    let first = true;

    // since we allow for trailing ',', we have to check for the closing ')'
    while !p.check(tok.TokenType.RParen) {
        // there should be no comma infront of the first parameter, so we can just skip this
        if !first {
            // every other parameter should be preceeded by a ','
            if p.consume(tok.TokenType.Comma).is_error() {
                return Result.Error;
            }

            // this allows for a trailing comma after the last parameter
            if p.check(tok.TokenType.RParen) {
                break;
            }
        }
        first = false;

        // a parameter has the form 'name: ty'
        let name: ident.Ident = undefined;
        if p.consume_ident(&name).is_error() {
            return Result.Error;
        }

        if p.consume(tok.TokenType.Colon).is_error() {
            return Result.Error;
        }

        let ty = p.alloc_tyid();
        if p.consume_tyid(ty).is_error() {
            return Result.Error;
        }

        let param = sig.param(name, ty);
        params.push(&param as *void);
    }

    let closing_rparen: tok.Token = undefined;
    if p.consume_tok(tok.TokenType.RParen, &closing_rparen).is_error() {
        return Result.Error;
    }

    *rparen_span = closing_rparen.span;
    return Result.OK;
}

def (p: *Parser) parse_block(memory: *Stmt): Result {
    let left_brace: tok.Token = undefined;
    if p.consume_tok(tok.TokenType.LBrace, &left_brace).is_error() {
        return Result.Error;
    }

    let block = &memory.data.block;
    let result = Result.OK;
    while !(p.is_at_end() || p.check(tok.TokenType.RBrace)) {
        let stmt = p.alloc_stmt();
        if p.statement(stmt).is_error() {
            result = Result.Error;
            continue;
        }
        block.push(stmt);
    }

    let right_brace: tok.Token = undefined;
    if p.consume_tok(tok.TokenType.RBrace, &right_brace).is_error() {
        return Result.Error;
    }

    memory.span = left_brace.span.merge(right_brace.span);
    return result;
}

def (p: *Parser) parse_if(memory: *Stmt): Result {
    let ifelse = &memory.data.ifelse;

    let if_token: tok.Token = undefined;
    if p.consume_tok(tok.TokenType.If, &if_token).is_error() {
        return Result.Error;
    }

    let condition = p.alloc_expr();
    if p.expression(condition, true).is_error() {
        return Result.Error;
    }
    ifelse.condition = condition;

    // technically, we could just parse another statement here like c or java do it, but
    // personally i think that braces should be required
    if !p.check(tok.TokenType.LBrace) {
        // TODO: report error
        return Result.Error;
    }

    let if_block = ifelse.if_block = p.alloc_stmt();
    if p.statement(if_block).is_error() {
        return Result.Error;
    }

    let end = if_block.span.end;
    ifelse.if_block = if_block;

    let else_block: *Stmt = null;
    if p.check(tok.TokenType.Else) {
        if p.consume(tok.TokenType.Else).is_error() {
            return Result.Error;
        }

        // here we allow either another 'if', or '{'
        if !(p.check(tok.TokenType.If) || p.check(tok.TokenType.LBrace)) {
            // TODO: report error here
            return Result.Error;
        }

        else_block = p.alloc_stmt();
        if p.statement(else_block).is_error() {
            return Result.Error;
        }

        ifelse.else_block = else_block;
        end = else_block.span.end;
    }

    memory.span = span.create(if_token.span.start, end);
    return Result.OK;
}

def (p: *Parser) parse_let_binding(memory: *Stmt): Result {
    let local = &memory.data.local;

    let let_tok: tok.Token = undefined;
    if p.consume_tok(tok.TokenType.Let, &let_tok).is_error() {
        return Result.Error;
    }

    let name: ident.Ident = undefined;
    if p.consume_ident(&name).is_error() {
        return Result.Error;
    }
    local.name = name;

    // a let statement may have an optional type identifier, which can change the type of the expr
    // let i = 0;       // sizeof(i) == 4
    // let i: i64 = 0;  // sizeof(i) == 8
    if p.consume_optional(tok.TokenType.Colon) {
        let ty = p.alloc_tyid();
        if p.consume_tyid(ty).is_error() {
            return Result.Error;
        }

        local.ty = ty;
    }

    if p.consume(tok.TokenType.Eq).is_error() {
        return Result.Error;
    }

    local.value = p.alloc_expr();
    if p.expression(local.value, false).is_error() {
        return Result.Error;
    }

    return Result.OK;
}

// parse a single expression
// the no_struct disallows struct literals, which is needed to differentiate a struct literal from
// the beginning of the block in if/while/for statements
// if x { ... is ambiguous without further context
def (p: *Parser) expression(memory: *Expr, no_struct: bool): Result {
    return p.parse_precedence(memory, tok.Precedence.Assign, no_struct);
}

// parse an expression with a certain start precedence (current). This will consume tokens
// until a token with a lower precedence than 'current' is found
// the resulting expression is stored in 'memory'
def (p: *Parser) parse_precedence(memory: *Expr, current: tok.Precedence, no_struct: bool): Result {
    if p.parse_prefix(memory, no_struct).is_error() {
        return Result.Error;
    }

    while p.next_higher_or_eq_precedence(current, no_struct) {
        // copy the old prefix expression data...
        let prefix = p.alloc_expr();
        *prefix = *memory;
        // ... since we overwrite it here
        if p.parse_infix(memory, prefix, no_struct).is_error() {
            return Result.Error;
        }
    }

    return Result.OK;
}

def (p: *Parser) next_higher_or_eq_precedence(current: tok.Precedence, no_struct: bool): bool {
    let lookahead = p.peek();
    if lookahead.ty == tok.TokenType.LBrace {
        return !no_struct && lookahead.ty.precedence() >= current;
    }

    return lookahead.ty.precedence() >= current;
}

// get the unary kind of a token type
// if ty is not in {'-', '*', '&', '!', '~'} then this will return false
// otherwise kind will be filled with the matching unary type
def is_unary_token(ty: tok.TokenType, kind: *UnaryKind): bool {
    if ty == tok.TokenType.Minus {
        *kind = UnaryKind.NumNegate;
        return true;
    }
    if ty == tok.TokenType.Star {
        *kind = UnaryKind.Deref;
        return true;
    }
    if ty == tok.TokenType.Ampersand {
        *kind = UnaryKind.AddrOf;
        return true;
    }
    if ty == tok.TokenType.Bang {
        *kind = UnaryKind.BoolNegate;
        return true;
    }
    if ty == tok.TokenType.Tilde {
        *kind = UnaryKind.BitNegate;
        return true;
    }

    return false;
}

// parse a prefix expression. e.g. a literal or a unary expression
// the parsed expression will be initialized into 'memory'
def (p: *Parser) parse_prefix(memory: *Expr, no_struct: bool): Result {
    let token = p.advance();

    if token.ty.is_literal() {
        memory.init_lit(token);
        return Result.OK;
    }

    if token.ty == tok.TokenType.Ident {
        memory.init_ident(ident.from_span(token.span));
        return Result.OK;
    }

    if token.ty == tok.TokenType.LParen {
        let start_span = token.span;
        // ignore no_struct, because the expression is in parentheses
        if p.expression(memory, false).is_error() {
            return Result.Error;
        }
        if p.consume_tok(tok.TokenType.RParen, &token).is_error() {
            return Result.Error;
        }

        memory.span = start_span.merge(token.span);
        return Result.OK;
    }

    if token.ty == tok.TokenType.Sizeof {
        let ty = p.alloc_tyid();
        if p.consume_tyid(ty).is_error() {
            return Result.Error;
        }

        memory.init_sizeof(ty);
        return Result.OK;
    }

    let unary_kind: UnaryKind = undefined;
    if is_unary_token(token.ty, &unary_kind) {
        // TODO(#6): for UnaryKind.AddrOf, check if right is an lvalue
        let right = p.alloc_expr();
        if p.parse_precedence(right, tok.Precedence.Unary, no_struct).is_error() {
            return Result.Error;
        }

        memory.init_unary(unary_kind, token, right);
        return Result.OK;
    }

    p.report_simple(e.ErrorKind.ExpectedExpression, token.span);
    return Result.Error;
}

// parse an infix expression. e.g. a binary expression
// the parsed expression will be initialized into 'memory'
def (p: *Parser) parse_infix(memory: *Expr, left: *Expr, no_struct: bool): Result {
    let token = p.advance();

    // binary expressions
    if token.ty.is_between(tok.TokenType.Plus, tok.TokenType.DoublePipe) {
        let right = p.alloc_expr();
        // calling parse_precedence with a higher precedence makes the expression left-associative
        // using the same precedence would make it right-associative
        let precedence = token.ty.precedence().next_higher();
        if p.parse_precedence(right, precedence, no_struct).is_error() {
            return Result.Error;
        }

        let offset = token.ty as i32 - tok.TokenType.Plus as i32;
        memory.init_binary(BinaryKind.Add.with_offset(offset), left, right, token.span);
        return Result.OK;
    }

    // TODO(#14): assignment parsing needs tests
    // TODO(#20): check if left is an lvalue
    // assignments
    if token.ty.is_between(tok.TokenType.Eq, tok.TokenType.CaretEq) {
        let right = p.alloc_expr();
        // using the same precedence makes assignments right-associative
        let precedence = token.ty.precedence();
        if p.parse_precedence(right, precedence, no_struct).is_error() {
            return Result.Error;
        }

        let offset = token.ty as i32 - tok.TokenType.Eq as i32;
        memory.init_assign(AssignKind.Eq.with_offset(offset), left, right);
        return Result.OK;
    }

    // access expression
    if token.ty == tok.TokenType.Dot {
        let identifier: ident.Ident = undefined;
        if p.consume_ident(&identifier).is_error() {
            return Result.Error;
        }

        let right = p.alloc_expr().init_ident(identifier);
        memory.init_access(left, right);
        return Result.OK;
    }

    // call expression
    if token.ty == tok.TokenType.LParen {
        memory.init_call(left);
        if p.parse_arg_list(memory).is_error() {
            return Result.Error;
        }

        return Result.OK;
    }

    p.report_simple(e.ErrorKind.ExpectedOperator, token.span);
    return Result.Error;
}

def (p: *Parser) parse_arg_list(memory: *Expr): Result {
    let call = &memory.data.call;

    let first = true;
    let previous: *ExprNode = null;
    let current = &call.args_head;

    // since we allow for trailing ',', we have to check for the closing ')'
    while !p.check(tok.TokenType.RParen) {
        // there should be no comma infront of the first parameter, so we can just skip this
        if !first {
            // every other parameter should be preceeded by a ','
            if p.consume(tok.TokenType.Comma).is_error() {
                return Result.Error;
            }

            // this allows for a trailing comma after the last parameter
            if p.check(tok.TokenType.RParen) {
                break;
            }
        }
        first = false;

        let node = p.alloc_expr_node();
        node.next = null;

        *current = node;
        if p.expression(&node.value, false).is_error() {
            return Result.Error;
        }

        if previous != null {
            previous.next = *current;
        }

        previous = *current;
        current = &(*current).next;
        call.num_args += 1;
    }

    let closing_rparen: tok.Token = undefined;
    if p.consume_tok(tok.TokenType.RParen, &closing_rparen).is_error() {
        return Result.Error;
    }

    memory.span = memory.span.merge(closing_rparen.span);
    return Result.OK;
}

